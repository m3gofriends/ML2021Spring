{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "73ae7095",
      "metadata": {
        "papermill": {
          "duration": 0.005364,
          "end_time": "2022-10-21T08:08:54.927645",
          "exception": false,
          "start_time": "2022-10-21T08:08:54.922281",
          "status": "completed"
        },
        "tags": [],
        "id": "73ae7095"
      },
      "source": [
        "### Strong baseline : 0.76023\n",
        "### ---Public : 0.75421, Private : 0.75370---\n",
        "### Simple baseline : 0.68334"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7145b353",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-21T08:08:54.938836Z",
          "iopub.status.busy": "2022-10-21T08:08:54.938237Z",
          "iopub.status.idle": "2022-10-21T08:09:11.411942Z",
          "shell.execute_reply": "2022-10-21T08:09:11.410728Z"
        },
        "papermill": {
          "duration": 16.483061,
          "end_time": "2022-10-21T08:09:11.415222",
          "exception": false,
          "start_time": "2022-10-21T08:08:54.932161",
          "status": "completed"
        },
        "tags": [],
        "id": "7145b353",
        "outputId": "6e3fa7ae-50d8-4157-8600-c8408fe803df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers==4.5.0\r\n",
            "  Downloading transformers-4.5.0-py3-none-any.whl (2.1 MB)\r\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\r\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\r\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0) (1.21.6)\r\n",
            "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0) (4.13.0)\r\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0) (2.28.1)\r\n",
            "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0) (4.64.0)\r\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0) (3.7.1)\r\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0) (2021.11.10)\r\n",
            "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0) (21.3)\r\n",
            "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0) (0.0.53)\r\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers==4.5.0) (4.1.1)\r\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers==4.5.0) (3.8.0)\r\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers==4.5.0) (3.0.9)\r\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.5.0) (2.1.0)\r\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.5.0) (1.26.12)\r\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.5.0) (2022.9.24)\r\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.5.0) (3.3)\r\n",
            "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.5.0) (1.0.1)\r\n",
            "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.5.0) (8.0.4)\r\n",
            "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.5.0) (1.15.0)\r\n",
            "Installing collected packages: tokenizers, transformers\r\n",
            "  Attempting uninstall: tokenizers\r\n",
            "    Found existing installation: tokenizers 0.12.1\r\n",
            "    Uninstalling tokenizers-0.12.1:\r\n",
            "      Successfully uninstalled tokenizers-0.12.1\r\n",
            "  Attempting uninstall: transformers\r\n",
            "    Found existing installation: transformers 4.20.1\r\n",
            "    Uninstalling transformers-4.20.1:\r\n",
            "      Successfully uninstalled transformers-4.20.1\r\n",
            "Successfully installed tokenizers-0.10.3 transformers-4.5.0\r\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.5.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4813116c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-21T08:09:11.426957Z",
          "iopub.status.busy": "2022-10-21T08:09:11.426551Z",
          "iopub.status.idle": "2022-10-21T08:09:18.225027Z",
          "shell.execute_reply": "2022-10-21T08:09:18.223924Z"
        },
        "papermill": {
          "duration": 6.808212,
          "end_time": "2022-10-21T08:09:18.228282",
          "exception": false,
          "start_time": "2022-10-21T08:09:11.420070",
          "status": "completed"
        },
        "tags": [],
        "id": "4813116c"
      },
      "outputs": [],
      "source": [
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# For data preprocess\n",
        "import numpy as np\n",
        "import csv\n",
        "import os\n",
        "\n",
        "# For plotting\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "myseed = 1234  # set a random seed for reproducibility\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(myseed)\n",
        "torch.manual_seed(myseed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(myseed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf13312b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-21T08:09:18.245602Z",
          "iopub.status.busy": "2022-10-21T08:09:18.244682Z",
          "iopub.status.idle": "2022-10-21T08:10:00.941476Z",
          "shell.execute_reply": "2022-10-21T08:10:00.939657Z"
        },
        "papermill": {
          "duration": 42.708169,
          "end_time": "2022-10-21T08:10:00.944262",
          "exception": false,
          "start_time": "2022-10-21T08:09:18.236093",
          "status": "completed"
        },
        "tags": [],
        "id": "bf13312b",
        "outputId": "873e6499-62b0-44c7-dd50-c0038c4a7903"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data ...\n",
            "Size of training data: (1229932, 429)\n",
            "Size of testing data: (451552, 11, 39)\n"
          ]
        }
      ],
      "source": [
        "print('Loading data ...')\n",
        "\n",
        "train = np.load('../input/ml2021spring-hw2/timit_11/timit_11/train_11.npy')\n",
        "train_label = np.load('../input/ml2021spring-hw2/timit_11/timit_11/train_label_11.npy')\n",
        "test = np.load('../input/ml2021spring-hw2/timit_11/timit_11/test_11.npy').reshape((451552, 11, 39))\n",
        "\n",
        "print('Size of training data: {}'.format(train.shape))\n",
        "print('Size of testing data: {}'.format(test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a39c58d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-21T08:10:00.955246Z",
          "iopub.status.busy": "2022-10-21T08:10:00.954872Z",
          "iopub.status.idle": "2022-10-21T08:10:00.962492Z",
          "shell.execute_reply": "2022-10-21T08:10:00.961335Z"
        },
        "papermill": {
          "duration": 0.016107,
          "end_time": "2022-10-21T08:10:00.965215",
          "exception": false,
          "start_time": "2022-10-21T08:10:00.949108",
          "status": "completed"
        },
        "tags": [],
        "id": "0a39c58d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TIMITDataset(Dataset):\n",
        "    def __init__(self, X, y=None):\n",
        "        self.data = torch.from_numpy(X).float()\n",
        "        if y is not None:\n",
        "            y = y.astype(int)\n",
        "            self.label = torch.LongTensor(y)\n",
        "        else:\n",
        "            self.label = None\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.label is not None:\n",
        "            return self.data[idx], self.label[idx]\n",
        "        else:\n",
        "            return self.data[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0582cac5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-21T08:10:00.976457Z",
          "iopub.status.busy": "2022-10-21T08:10:00.976055Z",
          "iopub.status.idle": "2022-10-21T08:10:00.983588Z",
          "shell.execute_reply": "2022-10-21T08:10:00.982595Z"
        },
        "papermill": {
          "duration": 0.016348,
          "end_time": "2022-10-21T08:10:00.986551",
          "exception": false,
          "start_time": "2022-10-21T08:10:00.970203",
          "status": "completed"
        },
        "tags": [],
        "id": "0582cac5",
        "outputId": "46b42eba-5f1f-4c21-aa71-6dbcc2631e26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of training set: (1106938, 11, 39)\n",
            "Size of validation set: (122994, 11, 39)\n"
          ]
        }
      ],
      "source": [
        "VAL_RATIO = 0.1\n",
        "\n",
        "percent = int(train.shape[0] * (1 - VAL_RATIO))\n",
        "train_x, train_y, val_x, val_y = train[:percent], train_label[:percent], train[percent:], train_label[percent:]\n",
        "\n",
        "train_shape = train_x.shape[0]\n",
        "train_x = train_x.reshape((train_x.shape[0], 11, 39))\n",
        "val_x = val_x.reshape((val_x.shape[0], 11, 39))\n",
        "\n",
        "print('Size of training set: {}'.format(train_x.shape))\n",
        "print('Size of validation set: {}'.format(val_x.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94dd67de",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-21T08:10:00.999264Z",
          "iopub.status.busy": "2022-10-21T08:10:00.998209Z",
          "iopub.status.idle": "2022-10-21T08:10:03.401289Z",
          "shell.execute_reply": "2022-10-21T08:10:03.400188Z"
        },
        "papermill": {
          "duration": 2.413368,
          "end_time": "2022-10-21T08:10:03.405596",
          "exception": false,
          "start_time": "2022-10-21T08:10:00.992228",
          "status": "completed"
        },
        "tags": [],
        "id": "94dd67de"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 512\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_set = TIMITDataset(train_x, train_y)\n",
        "val_set = TIMITDataset(val_x, val_y)\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True) #only shuffle the training data\n",
        "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "293e4c8b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-21T08:10:03.417439Z",
          "iopub.status.busy": "2022-10-21T08:10:03.417103Z",
          "iopub.status.idle": "2022-10-21T08:10:03.595943Z",
          "shell.execute_reply": "2022-10-21T08:10:03.594881Z"
        },
        "papermill": {
          "duration": 0.18738,
          "end_time": "2022-10-21T08:10:03.598553",
          "exception": false,
          "start_time": "2022-10-21T08:10:03.411173",
          "status": "completed"
        },
        "tags": [],
        "id": "293e4c8b",
        "outputId": "4d835a01-9ed8-43b0-ed5b-d1eee02c69e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "160"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gc\n",
        "\n",
        "del train, train_label, train_x, train_y, val_x, val_y\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec6c8d5a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-21T08:10:03.609811Z",
          "iopub.status.busy": "2022-10-21T08:10:03.609501Z",
          "iopub.status.idle": "2022-10-21T08:10:03.619482Z",
          "shell.execute_reply": "2022-10-21T08:10:03.618627Z"
        },
        "papermill": {
          "duration": 0.018072,
          "end_time": "2022-10-21T08:10:03.621568",
          "exception": false,
          "start_time": "2022-10-21T08:10:03.603496",
          "status": "completed"
        },
        "tags": [],
        "id": "ec6c8d5a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.layer1 = nn.Linear(39, 512)\n",
        "        self.layer2 = nn.Linear(512, 512)\n",
        "        self.layer3 = nn.Linear(512, 512)\n",
        "        self.layer4 = nn.Linear(5632, 512)\n",
        "        self.out = nn.Linear(512, 39) \n",
        "\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.act_fn = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.act_fn(x)\n",
        "\n",
        "        x = self.layer2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.act_fn(x)\n",
        "        \n",
        "        x = self.layer3(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.act_fn(x)\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.layer4(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.act_fn(x)\n",
        "\n",
        "        x = self.out(x)\n",
        "        \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4da5109e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-21T08:10:03.632274Z",
          "iopub.status.busy": "2022-10-21T08:10:03.631985Z",
          "iopub.status.idle": "2022-10-21T08:10:03.636551Z",
          "shell.execute_reply": "2022-10-21T08:10:03.635465Z"
        },
        "papermill": {
          "duration": 0.012522,
          "end_time": "2022-10-21T08:10:03.638914",
          "exception": false,
          "start_time": "2022-10-21T08:10:03.626392",
          "status": "completed"
        },
        "tags": [],
        "id": "4da5109e"
      },
      "outputs": [],
      "source": [
        "#check device\n",
        "def get_device():\n",
        "  return 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37e890c9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-21T08:10:03.649557Z",
          "iopub.status.busy": "2022-10-21T08:10:03.649283Z",
          "iopub.status.idle": "2022-10-21T08:10:08.542220Z",
          "shell.execute_reply": "2022-10-21T08:10:08.541192Z"
        },
        "papermill": {
          "duration": 4.901122,
          "end_time": "2022-10-21T08:10:08.544780",
          "exception": false,
          "start_time": "2022-10-21T08:10:03.643658",
          "status": "completed"
        },
        "tags": [],
        "id": "37e890c9",
        "outputId": "368a508e-b7b6-44f8-841b-609ea9712486"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEVICE: cuda\n"
          ]
        }
      ],
      "source": [
        "# get device \n",
        "device = get_device()\n",
        "print(f'DEVICE: {device}')\n",
        "\n",
        "# training parameters\n",
        "num_epoch = 200               # number of training epoch\n",
        "learning_rate = 0.0001       # learning rate\n",
        "\n",
        "# the path where checkpoint saved\n",
        "model_path = './model.ckpt'\n",
        "\n",
        "# create model, define a loss function, and optimizer\n",
        "model = Classifier().to(device)\n",
        "criterion = nn.CrossEntropyLoss() \n",
        "#optimizer = torch.optim.RAdam(model.parameters(),lr=learning_rate, weight_decay=1e-7)\n",
        "\n",
        "steps = (train_shape // BATCH_SIZE) + 1\n",
        "total_steps = num_epoch * steps\n",
        "warm_up_ratio = 0.1\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-7)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = warm_up_ratio * total_steps, num_training_steps = total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cecc4eb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-21T08:10:08.558053Z",
          "iopub.status.busy": "2022-10-21T08:10:08.556165Z",
          "iopub.status.idle": "2022-10-21T08:10:08.561655Z",
          "shell.execute_reply": "2022-10-21T08:10:08.560660Z"
        },
        "papermill": {
          "duration": 0.013652,
          "end_time": "2022-10-21T08:10:08.563728",
          "exception": false,
          "start_time": "2022-10-21T08:10:08.550076",
          "status": "completed"
        },
        "tags": [],
        "id": "5cecc4eb"
      },
      "outputs": [],
      "source": [
        "ES_patience = 10\n",
        "ES_counter = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a972d88",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-21T08:10:08.576859Z",
          "iopub.status.busy": "2022-10-21T08:10:08.576468Z",
          "iopub.status.idle": "2022-10-21T08:48:56.751928Z",
          "shell.execute_reply": "2022-10-21T08:48:56.749429Z"
        },
        "papermill": {
          "duration": 2328.185687,
          "end_time": "2022-10-21T08:48:56.755706",
          "exception": false,
          "start_time": "2022-10-21T08:10:08.570019",
          "status": "completed"
        },
        "tags": [],
        "id": "1a972d88",
        "outputId": "9d350045-7487-4b8e-e43a-0c36a0dd9dd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[001/200] Train Acc: 0.153575 Loss: 3.284063 | Val Acc: 0.296177 loss: 2.585336\n",
            "saving model with loss 2.585\n",
            "[002/200] Train Acc: 0.368069 Loss: 2.221238 | Val Acc: 0.482804 loss: 1.731434\n",
            "saving model with loss 1.731\n",
            "[003/200] Train Acc: 0.458246 Loss: 1.810318 | Val Acc: 0.546230 loss: 1.493983\n",
            "saving model with loss 1.494\n",
            "[004/200] Train Acc: 0.507867 Loss: 1.620983 | Val Acc: 0.589923 loss: 1.337333\n",
            "saving model with loss 1.337\n",
            "[005/200] Train Acc: 0.545036 Loss: 1.484796 | Val Acc: 0.621990 loss: 1.220077\n",
            "saving model with loss 1.220\n",
            "[006/200] Train Acc: 0.573303 Loss: 1.384474 | Val Acc: 0.642259 loss: 1.139564\n",
            "saving model with loss 1.140\n",
            "[007/200] Train Acc: 0.594347 Loss: 1.307042 | Val Acc: 0.659642 loss: 1.073281\n",
            "saving model with loss 1.073\n",
            "[008/200] Train Acc: 0.610634 Loss: 1.246435 | Val Acc: 0.672651 loss: 1.023288\n",
            "saving model with loss 1.023\n",
            "[009/200] Train Acc: 0.624605 Loss: 1.195716 | Val Acc: 0.683619 loss: 0.980145\n",
            "saving model with loss 0.980\n",
            "[010/200] Train Acc: 0.636252 Loss: 1.154363 | Val Acc: 0.694676 loss: 0.944348\n",
            "saving model with loss 0.944\n",
            "[011/200] Train Acc: 0.646128 Loss: 1.118835 | Val Acc: 0.700571 loss: 0.920649\n",
            "saving model with loss 0.921\n",
            "[012/200] Train Acc: 0.654702 Loss: 1.086824 | Val Acc: 0.705254 loss: 0.901147\n",
            "saving model with loss 0.901\n",
            "[013/200] Train Acc: 0.661759 Loss: 1.060388 | Val Acc: 0.710896 loss: 0.878521\n",
            "saving model with loss 0.879\n",
            "[014/200] Train Acc: 0.668799 Loss: 1.035458 | Val Acc: 0.716238 loss: 0.859789\n",
            "saving model with loss 0.860\n",
            "[015/200] Train Acc: 0.674572 Loss: 1.014338 | Val Acc: 0.720141 loss: 0.845098\n",
            "saving model with loss 0.845\n",
            "[016/200] Train Acc: 0.680078 Loss: 0.994449 | Val Acc: 0.723564 loss: 0.832906\n",
            "saving model with loss 0.833\n",
            "[017/200] Train Acc: 0.685714 Loss: 0.975499 | Val Acc: 0.727271 loss: 0.819245\n",
            "saving model with loss 0.819\n",
            "[018/200] Train Acc: 0.689738 Loss: 0.960189 | Val Acc: 0.730873 loss: 0.806843\n",
            "saving model with loss 0.807\n",
            "[019/200] Train Acc: 0.693176 Loss: 0.945178 | Val Acc: 0.732914 loss: 0.797431\n",
            "saving model with loss 0.797\n",
            "[020/200] Train Acc: 0.697512 Loss: 0.930404 | Val Acc: 0.736784 loss: 0.790335\n",
            "saving model with loss 0.790\n",
            "[021/200] Train Acc: 0.701179 Loss: 0.917470 | Val Acc: 0.738312 loss: 0.781412\n",
            "saving model with loss 0.781\n",
            "[022/200] Train Acc: 0.704675 Loss: 0.904318 | Val Acc: 0.741378 loss: 0.773173\n",
            "saving model with loss 0.773\n",
            "[023/200] Train Acc: 0.708103 Loss: 0.893488 | Val Acc: 0.742996 loss: 0.765561\n",
            "saving model with loss 0.766\n",
            "[024/200] Train Acc: 0.710395 Loss: 0.882782 | Val Acc: 0.744451 loss: 0.759922\n",
            "saving model with loss 0.760\n",
            "[025/200] Train Acc: 0.712971 Loss: 0.873660 | Val Acc: 0.745549 loss: 0.755315\n",
            "saving model with loss 0.755\n",
            "[026/200] Train Acc: 0.716046 Loss: 0.864785 | Val Acc: 0.747012 loss: 0.750159\n",
            "saving model with loss 0.750\n",
            "[027/200] Train Acc: 0.717725 Loss: 0.856894 | Val Acc: 0.748134 loss: 0.748375\n",
            "saving model with loss 0.748\n",
            "[028/200] Train Acc: 0.719667 Loss: 0.849583 | Val Acc: 0.749305 loss: 0.742205\n",
            "saving model with loss 0.742\n",
            "[029/200] Train Acc: 0.721637 Loss: 0.843458 | Val Acc: 0.750305 loss: 0.739443\n",
            "saving model with loss 0.739\n",
            "[030/200] Train Acc: 0.723171 Loss: 0.836636 | Val Acc: 0.751037 loss: 0.736113\n",
            "saving model with loss 0.736\n",
            "[031/200] Train Acc: 0.724704 Loss: 0.830851 | Val Acc: 0.751476 loss: 0.734607\n",
            "saving model with loss 0.735\n",
            "[032/200] Train Acc: 0.726352 Loss: 0.825469 | Val Acc: 0.753768 loss: 0.728058\n",
            "saving model with loss 0.728\n",
            "[033/200] Train Acc: 0.727792 Loss: 0.819556 | Val Acc: 0.753053 loss: 0.732518\n",
            "[034/200] Train Acc: 0.729111 Loss: 0.814414 | Val Acc: 0.754695 loss: 0.728346\n",
            "[035/200] Train Acc: 0.730875 Loss: 0.809065 | Val Acc: 0.755232 loss: 0.725458\n",
            "saving model with loss 0.725\n",
            "[036/200] Train Acc: 0.731149 Loss: 0.806383 | Val Acc: 0.755077 loss: 0.724743\n",
            "saving model with loss 0.725\n",
            "[037/200] Train Acc: 0.732890 Loss: 0.801272 | Val Acc: 0.755923 loss: 0.723067\n",
            "saving model with loss 0.723\n",
            "[038/200] Train Acc: 0.733940 Loss: 0.796942 | Val Acc: 0.757330 loss: 0.721088\n",
            "saving model with loss 0.721\n",
            "[039/200] Train Acc: 0.735674 Loss: 0.793258 | Val Acc: 0.757590 loss: 0.717642\n",
            "saving model with loss 0.718\n",
            "[040/200] Train Acc: 0.735962 Loss: 0.789470 | Val Acc: 0.757817 loss: 0.716473\n",
            "saving model with loss 0.716\n",
            "[041/200] Train Acc: 0.736954 Loss: 0.786539 | Val Acc: 0.757907 loss: 0.713850\n",
            "saving model with loss 0.714\n",
            "[042/200] Train Acc: 0.738373 Loss: 0.781853 | Val Acc: 0.757793 loss: 0.716004\n",
            "[043/200] Train Acc: 0.738895 Loss: 0.779919 | Val Acc: 0.758557 loss: 0.714899\n",
            "[044/200] Train Acc: 0.740060 Loss: 0.776375 | Val Acc: 0.759411 loss: 0.713274\n",
            "saving model with loss 0.713\n",
            "[045/200] Train Acc: 0.740698 Loss: 0.773498 | Val Acc: 0.759452 loss: 0.712488\n",
            "saving model with loss 0.712\n",
            "[046/200] Train Acc: 0.741330 Loss: 0.770353 | Val Acc: 0.760761 loss: 0.711320\n",
            "saving model with loss 0.711\n",
            "[047/200] Train Acc: 0.742483 Loss: 0.768094 | Val Acc: 0.760517 loss: 0.710452\n",
            "saving model with loss 0.710\n",
            "[048/200] Train Acc: 0.742762 Loss: 0.764918 | Val Acc: 0.760070 loss: 0.711145\n",
            "[049/200] Train Acc: 0.743558 Loss: 0.761932 | Val Acc: 0.760907 loss: 0.709554\n",
            "saving model with loss 0.710\n",
            "[050/200] Train Acc: 0.744258 Loss: 0.760316 | Val Acc: 0.760533 loss: 0.708728\n",
            "saving model with loss 0.709\n",
            "[051/200] Train Acc: 0.745269 Loss: 0.757107 | Val Acc: 0.761240 loss: 0.706868\n",
            "saving model with loss 0.707\n",
            "[052/200] Train Acc: 0.745320 Loss: 0.754951 | Val Acc: 0.761468 loss: 0.708527\n",
            "[053/200] Train Acc: 0.745940 Loss: 0.753399 | Val Acc: 0.761574 loss: 0.708470\n",
            "[054/200] Train Acc: 0.746394 Loss: 0.751860 | Val Acc: 0.762753 loss: 0.707052\n",
            "[055/200] Train Acc: 0.747485 Loss: 0.747563 | Val Acc: 0.762769 loss: 0.703515\n",
            "saving model with loss 0.704\n",
            "[056/200] Train Acc: 0.747970 Loss: 0.747091 | Val Acc: 0.761330 loss: 0.708767\n",
            "[057/200] Train Acc: 0.748504 Loss: 0.745118 | Val Acc: 0.762143 loss: 0.705462\n",
            "[058/200] Train Acc: 0.748943 Loss: 0.743195 | Val Acc: 0.762858 loss: 0.704511\n",
            "[059/200] Train Acc: 0.749376 Loss: 0.741340 | Val Acc: 0.761980 loss: 0.706027\n",
            "[060/200] Train Acc: 0.749927 Loss: 0.739416 | Val Acc: 0.762582 loss: 0.705334\n",
            "[061/200] Train Acc: 0.750881 Loss: 0.737115 | Val Acc: 0.763224 loss: 0.703498\n",
            "saving model with loss 0.703\n",
            "[062/200] Train Acc: 0.750890 Loss: 0.735556 | Val Acc: 0.763948 loss: 0.702022\n",
            "saving model with loss 0.702\n",
            "[063/200] Train Acc: 0.751419 Loss: 0.734378 | Val Acc: 0.764297 loss: 0.701593\n",
            "saving model with loss 0.702\n",
            "[064/200] Train Acc: 0.751520 Loss: 0.733646 | Val Acc: 0.763476 loss: 0.703434\n",
            "[065/200] Train Acc: 0.752018 Loss: 0.731892 | Val Acc: 0.764021 loss: 0.701096\n",
            "saving model with loss 0.701\n",
            "[066/200] Train Acc: 0.752219 Loss: 0.730048 | Val Acc: 0.764989 loss: 0.701560\n",
            "[067/200] Train Acc: 0.752661 Loss: 0.728389 | Val Acc: 0.764728 loss: 0.701616\n",
            "[068/200] Train Acc: 0.753485 Loss: 0.726945 | Val Acc: 0.764265 loss: 0.703681\n",
            "[069/200] Train Acc: 0.753218 Loss: 0.725902 | Val Acc: 0.765086 loss: 0.701587\n",
            "[070/200] Train Acc: 0.754090 Loss: 0.723793 | Val Acc: 0.765541 loss: 0.700032\n",
            "saving model with loss 0.700\n",
            "[071/200] Train Acc: 0.754227 Loss: 0.722760 | Val Acc: 0.765419 loss: 0.700672\n",
            "[072/200] Train Acc: 0.754378 Loss: 0.722749 | Val Acc: 0.764964 loss: 0.701862\n",
            "[073/200] Train Acc: 0.755028 Loss: 0.720885 | Val Acc: 0.766338 loss: 0.699278\n",
            "saving model with loss 0.699\n",
            "[074/200] Train Acc: 0.755798 Loss: 0.719394 | Val Acc: 0.766078 loss: 0.699546\n",
            "[075/200] Train Acc: 0.755511 Loss: 0.718383 | Val Acc: 0.766753 loss: 0.698632\n",
            "saving model with loss 0.699\n",
            "[076/200] Train Acc: 0.755896 Loss: 0.715983 | Val Acc: 0.765989 loss: 0.701720\n",
            "[077/200] Train Acc: 0.756216 Loss: 0.716327 | Val Acc: 0.766013 loss: 0.699417\n",
            "[078/200] Train Acc: 0.756451 Loss: 0.715331 | Val Acc: 0.765891 loss: 0.699663\n",
            "[079/200] Train Acc: 0.756817 Loss: 0.714055 | Val Acc: 0.766119 loss: 0.698279\n",
            "saving model with loss 0.698\n",
            "[080/200] Train Acc: 0.757096 Loss: 0.712516 | Val Acc: 0.766517 loss: 0.698899\n",
            "[081/200] Train Acc: 0.757489 Loss: 0.711300 | Val Acc: 0.766745 loss: 0.696759\n",
            "saving model with loss 0.697\n",
            "[082/200] Train Acc: 0.758319 Loss: 0.709897 | Val Acc: 0.766143 loss: 0.699185\n",
            "[083/200] Train Acc: 0.758356 Loss: 0.709978 | Val Acc: 0.766436 loss: 0.700866\n",
            "[084/200] Train Acc: 0.758135 Loss: 0.708515 | Val Acc: 0.766842 loss: 0.697041\n",
            "[085/200] Train Acc: 0.758569 Loss: 0.708345 | Val Acc: 0.766558 loss: 0.699556\n",
            "[086/200] Train Acc: 0.758566 Loss: 0.707152 | Val Acc: 0.766582 loss: 0.699106\n",
            "[087/200] Train Acc: 0.759252 Loss: 0.705559 | Val Acc: 0.766867 loss: 0.695132\n",
            "saving model with loss 0.695\n",
            "[088/200] Train Acc: 0.759218 Loss: 0.705099 | Val Acc: 0.766224 loss: 0.699575\n",
            "[089/200] Train Acc: 0.760011 Loss: 0.703746 | Val Acc: 0.767005 loss: 0.698347\n",
            "[090/200] Train Acc: 0.760436 Loss: 0.702669 | Val Acc: 0.766753 loss: 0.697538\n",
            "[091/200] Train Acc: 0.760174 Loss: 0.702890 | Val Acc: 0.767493 loss: 0.696527\n",
            "[092/200] Train Acc: 0.760621 Loss: 0.701034 | Val Acc: 0.767135 loss: 0.696886\n",
            "[093/200] Train Acc: 0.760330 Loss: 0.701140 | Val Acc: 0.766574 loss: 0.699970\n",
            "[094/200] Train Acc: 0.761175 Loss: 0.699885 | Val Acc: 0.766956 loss: 0.697185\n",
            "[095/200] Train Acc: 0.760975 Loss: 0.699255 | Val Acc: 0.766753 loss: 0.699350\n",
            "[096/200] Train Acc: 0.761257 Loss: 0.698078 | Val Acc: 0.767111 loss: 0.697328\n",
            "[097/200] Train Acc: 0.761461 Loss: 0.697634 | Val Acc: 0.766834 loss: 0.697615\n",
            "---Early Stopping---\n"
          ]
        }
      ],
      "source": [
        "# start training\n",
        "\n",
        "best_loss = 10.0\n",
        "for epoch in range(num_epoch):\n",
        "    train_acc = 0.0\n",
        "    train_loss = 0.0\n",
        "    val_acc = 0.0\n",
        "    val_loss = 0.0\n",
        "\n",
        "    # training\n",
        "    model.train() # set the model to training mode\n",
        "    for i, data in enumerate(train_loader):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad() \n",
        "        outputs = model(inputs) \n",
        "        batch_loss = criterion(outputs, labels)\n",
        "        _, train_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
        "        batch_loss.backward() \n",
        "        optimizer.step() \n",
        "        scheduler.step()\n",
        "\n",
        "        train_acc += (train_pred.cpu() == labels.cpu()).sum().item()\n",
        "        train_loss += batch_loss.item()\n",
        "\n",
        "    # validation\n",
        "    if len(val_set) > 0:\n",
        "        model.eval() # set the model to evaluation mode\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(val_loader):\n",
        "                inputs, labels = data\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                batch_loss = criterion(outputs, labels) \n",
        "                _, val_pred = torch.max(outputs, 1) \n",
        "            \n",
        "                val_acc += (val_pred.cpu() == labels.cpu()).sum().item() # get the index of the class with the highest probability\n",
        "                val_loss += batch_loss.item()\n",
        "\n",
        "            print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f} | Val Acc: {:3.6f} loss: {:3.6f}'.format(\n",
        "                epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader), val_acc/len(val_set), val_loss/len(val_loader)\n",
        "            ))\n",
        "\n",
        "            # if the model improves, save a checkpoint at this epoch\n",
        "            if val_loss/len(val_loader) < best_loss:\n",
        "                ES_counter = -1\n",
        "                best_loss = val_loss/len(val_loader)\n",
        "                torch.save(model.state_dict(), model_path)\n",
        "                print('saving model with loss {:.3f}'.format(best_loss))\n",
        "    else:\n",
        "        print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f}'.format(\n",
        "            epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader)\n",
        "        ))\n",
        "    ES_counter += 1  \n",
        "    if ES_counter == ES_patience:\n",
        "        print('---Early Stopping---')\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b325bfc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-21T08:48:56.779778Z",
          "iopub.status.busy": "2022-10-21T08:48:56.778837Z",
          "iopub.status.idle": "2022-10-21T08:48:57.587243Z",
          "shell.execute_reply": "2022-10-21T08:48:57.586237Z"
        },
        "papermill": {
          "duration": 0.822849,
          "end_time": "2022-10-21T08:48:57.589992",
          "exception": false,
          "start_time": "2022-10-21T08:48:56.767143",
          "status": "completed"
        },
        "tags": [],
        "id": "8b325bfc",
        "outputId": "cc16d96c-ac54-431a-8bdf-1402eb3fd269"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create testing dataset\n",
        "test_set = TIMITDataset(test, None)\n",
        "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# create model and load weights from checkpoint\n",
        "model = Classifier().to(device)\n",
        "model.load_state_dict(torch.load(model_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18aea135",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-21T08:48:57.622772Z",
          "iopub.status.busy": "2022-10-21T08:48:57.622132Z",
          "iopub.status.idle": "2022-10-21T08:49:00.668547Z",
          "shell.execute_reply": "2022-10-21T08:49:00.667466Z"
        },
        "papermill": {
          "duration": 3.066012,
          "end_time": "2022-10-21T08:49:00.671482",
          "exception": false,
          "start_time": "2022-10-21T08:48:57.605470",
          "status": "completed"
        },
        "tags": [],
        "id": "18aea135"
      },
      "outputs": [],
      "source": [
        "predict = []\n",
        "model.eval() # set the model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(test_loader):\n",
        "        inputs = data\n",
        "        inputs = inputs.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, test_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
        "\n",
        "        for y in test_pred.cpu().numpy():\n",
        "            predict.append(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06760a2e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-21T08:49:00.694434Z",
          "iopub.status.busy": "2022-10-21T08:49:00.694111Z",
          "iopub.status.idle": "2022-10-21T08:49:01.038175Z",
          "shell.execute_reply": "2022-10-21T08:49:01.037131Z"
        },
        "papermill": {
          "duration": 0.35847,
          "end_time": "2022-10-21T08:49:01.041004",
          "exception": false,
          "start_time": "2022-10-21T08:49:00.682534",
          "status": "completed"
        },
        "tags": [],
        "id": "06760a2e"
      },
      "outputs": [],
      "source": [
        "with open('submission.csv', 'w') as f:\n",
        "    f.write('Id,Class\\n')\n",
        "    for i, y in enumerate(predict):\n",
        "        f.write('{},{}\\n'.format(i, y))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 2418.530652,
      "end_time": "2022-10-21T08:49:04.821395",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-10-21T08:08:46.290743",
      "version": "2.3.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}